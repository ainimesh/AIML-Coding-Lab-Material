{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pragnent</th>\n",
       "      <th>glucose_concentration</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin_serum</th>\n",
       "      <th>bmi</th>\n",
       "      <th>dpf</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   times_pragnent  glucose_concentration  blood_pressure  skin_thickness  \\\n",
       "0               6                    148              72              35   \n",
       "1               1                     85              66              29   \n",
       "2               8                    183              64               0   \n",
       "3               1                     89              66              23   \n",
       "4               0                    137              40              35   \n",
       "\n",
       "   insulin_serum   bmi    dpf  age  class  \n",
       "0              0  33.6  0.627   50      1  \n",
       "1              0  26.6  0.351   31      0  \n",
       "2              0  23.3  0.672   32      1  \n",
       "3             94  28.1  0.167   21      0  \n",
       "4            168  43.1  2.288   33      1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "\n",
    "df = pd.read_csv('diabetes.csv', delimiter=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input (X) and output (y) variables\n",
    "X = df.iloc[:,0:8]\n",
    "y = df.iloc[:,8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pragnent</th>\n",
       "      <th>glucose_concentration</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin_serum</th>\n",
       "      <th>bmi</th>\n",
       "      <th>dpf</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pragnent  glucose_concentration  blood_pressure  skin_thickness  \\\n",
       "0                 6                    148              72              35   \n",
       "1                 1                     85              66              29   \n",
       "2                 8                    183              64               0   \n",
       "3                 1                     89              66              23   \n",
       "4                 0                    137              40              35   \n",
       "..              ...                    ...             ...             ...   \n",
       "763              10                    101              76              48   \n",
       "764               2                    122              70              27   \n",
       "765               5                    121              72              23   \n",
       "766               1                    126              60               0   \n",
       "767               1                     93              70              31   \n",
       "\n",
       "     insulin_serum   bmi    dpf  age  \n",
       "0                0  33.6  0.627   50  \n",
       "1                0  26.6  0.351   31  \n",
       "2                0  23.3  0.672   32  \n",
       "3               94  28.1  0.167   21  \n",
       "4              168  43.1  2.288   33  \n",
       "..             ...   ...    ...  ...  \n",
       "763            180  32.9  0.171   63  \n",
       "764              0  36.8  0.340   27  \n",
       "765            112  26.2  0.245   30  \n",
       "766              0  30.1  0.349   47  \n",
       "767              0  30.4  0.315   23  \n",
       "\n",
       "[768 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Tensorflow Model\n",
    "model = Sequential()\n",
    "\n",
    "# adding layers\n",
    "\n",
    "model.add(layers.Dense(12, input_shape=(8,), activation = 'relu'))\n",
    "model.add(layers.Dense(8, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 12)                108       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 221 (884.00 Byte)\n",
      "Trainable params: 221 (884.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.07891414, -0.09363458, -0.468769  , -0.3294229 , -0.4888745 ,\n",
       "        -0.49027178, -0.5453195 , -0.32760316, -0.05880749,  0.5077205 ,\n",
       "         0.30226964, -0.42945364],\n",
       "       [ 0.02620167, -0.25415817, -0.08669099,  0.31625473, -0.4570334 ,\n",
       "         0.14017093, -0.20094776,  0.5259173 , -0.09629399,  0.48114395,\n",
       "        -0.4466794 , -0.2582326 ],\n",
       "       [ 0.17173713,  0.5245031 ,  0.5431067 ,  0.11886871,  0.24697113,\n",
       "         0.24541062,  0.4334706 , -0.19091305, -0.18860191,  0.4148426 ,\n",
       "        -0.34744197,  0.1204654 ],\n",
       "       [ 0.46206045, -0.09202248,  0.23470521,  0.50019145,  0.3642667 ,\n",
       "         0.1675992 , -0.40189725, -0.23405999,  0.3264122 ,  0.35461318,\n",
       "         0.29219103,  0.29106092],\n",
       "       [ 0.49818325,  0.16130072, -0.17231926, -0.46056357, -0.39491645,\n",
       "         0.12729669,  0.33289027, -0.00406086, -0.23342705, -0.00918353,\n",
       "        -0.17865849,  0.17127913],\n",
       "       [ 0.04650801,  0.5259019 , -0.19091046,  0.42628425,  0.18100399,\n",
       "        -0.39816952, -0.2702521 , -0.5152209 ,  0.3995852 ,  0.36826462,\n",
       "         0.2011506 ,  0.21804684],\n",
       "       [ 0.161749  , -0.05985767,  0.35307866, -0.26342437,  0.2912867 ,\n",
       "         0.34504175, -0.4565262 , -0.07555163, -0.482322  , -0.49010867,\n",
       "         0.53008676,  0.53387487],\n",
       "       [-0.53057885,  0.24611413,  0.26906312, -0.24820572,  0.31873786,\n",
       "        -0.09125346, -0.18693772,  0.45009762, -0.16692823,  0.47963   ,\n",
       "         0.09939164,  0.1253969 ]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1,b1 = model.layers[0].get_weights()\n",
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 12)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Model\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5490 - accuracy: 0.7020\n",
      "Epoch 2/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5559 - accuracy: 0.6938\n",
      "Epoch 3/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5579 - accuracy: 0.7068\n",
      "Epoch 4/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5421 - accuracy: 0.7036\n",
      "Epoch 5/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5411 - accuracy: 0.7134\n",
      "Epoch 6/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5498 - accuracy: 0.7166\n",
      "Epoch 7/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5516 - accuracy: 0.6987\n",
      "Epoch 8/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5433 - accuracy: 0.7117\n",
      "Epoch 9/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5490 - accuracy: 0.7068\n",
      "Epoch 10/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5418 - accuracy: 0.7068\n",
      "Epoch 11/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5401 - accuracy: 0.7085\n",
      "Epoch 12/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5443 - accuracy: 0.7117\n",
      "Epoch 13/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5358 - accuracy: 0.7296\n",
      "Epoch 14/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5494 - accuracy: 0.7101\n",
      "Epoch 15/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5384 - accuracy: 0.7166\n",
      "Epoch 16/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5379 - accuracy: 0.7101\n",
      "Epoch 17/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5362 - accuracy: 0.7248\n",
      "Epoch 18/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5357 - accuracy: 0.7231\n",
      "Epoch 19/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5421 - accuracy: 0.7280\n",
      "Epoch 20/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5356 - accuracy: 0.7182\n",
      "Epoch 21/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5381 - accuracy: 0.7313\n",
      "Epoch 22/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5597 - accuracy: 0.7052\n",
      "Epoch 23/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5310 - accuracy: 0.7166\n",
      "Epoch 24/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5319 - accuracy: 0.7117\n",
      "Epoch 25/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5354 - accuracy: 0.7117\n",
      "Epoch 26/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5280 - accuracy: 0.7199\n",
      "Epoch 27/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5303 - accuracy: 0.7215\n",
      "Epoch 28/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5354 - accuracy: 0.7068\n",
      "Epoch 29/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5305 - accuracy: 0.7345\n",
      "Epoch 30/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5329 - accuracy: 0.7166\n",
      "Epoch 31/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5298 - accuracy: 0.7231\n",
      "Epoch 32/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5321 - accuracy: 0.7215\n",
      "Epoch 33/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5475 - accuracy: 0.7134\n",
      "Epoch 34/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5361 - accuracy: 0.7003\n",
      "Epoch 35/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5346 - accuracy: 0.7199\n",
      "Epoch 36/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5324 - accuracy: 0.7362\n",
      "Epoch 37/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5307 - accuracy: 0.7264\n",
      "Epoch 38/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5226 - accuracy: 0.7329\n",
      "Epoch 39/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5321 - accuracy: 0.7329\n",
      "Epoch 40/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5169 - accuracy: 0.7264\n",
      "Epoch 41/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5354 - accuracy: 0.7248\n",
      "Epoch 42/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5263 - accuracy: 0.7264\n",
      "Epoch 43/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5203 - accuracy: 0.7394\n",
      "Epoch 44/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5228 - accuracy: 0.7248\n",
      "Epoch 45/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5255 - accuracy: 0.7215\n",
      "Epoch 46/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5272 - accuracy: 0.7296\n",
      "Epoch 47/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5258 - accuracy: 0.7215\n",
      "Epoch 48/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5199 - accuracy: 0.7296\n",
      "Epoch 49/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5218 - accuracy: 0.7231\n",
      "Epoch 50/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5233 - accuracy: 0.7280\n",
      "Epoch 51/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5201 - accuracy: 0.7248\n",
      "Epoch 52/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5197 - accuracy: 0.7280\n",
      "Epoch 53/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5136 - accuracy: 0.7231\n",
      "Epoch 54/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5146 - accuracy: 0.7296\n",
      "Epoch 55/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5371 - accuracy: 0.7052\n",
      "Epoch 56/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5260 - accuracy: 0.7215\n",
      "Epoch 57/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5209 - accuracy: 0.7329\n",
      "Epoch 58/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5226 - accuracy: 0.7248\n",
      "Epoch 59/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5168 - accuracy: 0.7313\n",
      "Epoch 60/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5111 - accuracy: 0.7264\n",
      "Epoch 61/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5178 - accuracy: 0.7182\n",
      "Epoch 62/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5189 - accuracy: 0.7134\n",
      "Epoch 63/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5127 - accuracy: 0.7394\n",
      "Epoch 64/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5183 - accuracy: 0.7541\n",
      "Epoch 65/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5140 - accuracy: 0.7394\n",
      "Epoch 66/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5251 - accuracy: 0.7248\n",
      "Epoch 67/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5082 - accuracy: 0.7410\n",
      "Epoch 68/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5151 - accuracy: 0.7345\n",
      "Epoch 69/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5305 - accuracy: 0.7166\n",
      "Epoch 70/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5501 - accuracy: 0.7215\n",
      "Epoch 71/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5069 - accuracy: 0.7345\n",
      "Epoch 72/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5069 - accuracy: 0.7394\n",
      "Epoch 73/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5091 - accuracy: 0.7378\n",
      "Epoch 74/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5098 - accuracy: 0.7492\n",
      "Epoch 75/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5316 - accuracy: 0.7052\n",
      "Epoch 76/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5129 - accuracy: 0.7296\n",
      "Epoch 77/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5132 - accuracy: 0.7345\n",
      "Epoch 78/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5255 - accuracy: 0.7117\n",
      "Epoch 79/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5129 - accuracy: 0.7199\n",
      "Epoch 80/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5087 - accuracy: 0.7248\n",
      "Epoch 81/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5025 - accuracy: 0.7329\n",
      "Epoch 82/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5077 - accuracy: 0.7394\n",
      "Epoch 83/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5065 - accuracy: 0.7394\n",
      "Epoch 84/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5033 - accuracy: 0.7313\n",
      "Epoch 85/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5105 - accuracy: 0.7313\n",
      "Epoch 86/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4943 - accuracy: 0.7443\n",
      "Epoch 87/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5223 - accuracy: 0.7166\n",
      "Epoch 88/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5147 - accuracy: 0.7362\n",
      "Epoch 89/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4987 - accuracy: 0.7443\n",
      "Epoch 90/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5055 - accuracy: 0.7280\n",
      "Epoch 91/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5201 - accuracy: 0.7003\n",
      "Epoch 92/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5018 - accuracy: 0.7362\n",
      "Epoch 93/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5131 - accuracy: 0.7150\n",
      "Epoch 94/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5032 - accuracy: 0.7394\n",
      "Epoch 95/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4996 - accuracy: 0.7459\n",
      "Epoch 96/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5078 - accuracy: 0.7459\n",
      "Epoch 97/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5053 - accuracy: 0.7443\n",
      "Epoch 98/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4876 - accuracy: 0.7573\n",
      "Epoch 99/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4973 - accuracy: 0.7573\n",
      "Epoch 100/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4915 - accuracy: 0.7508\n",
      "Epoch 101/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5052 - accuracy: 0.7394\n",
      "Epoch 102/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5037 - accuracy: 0.7476\n",
      "Epoch 103/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4983 - accuracy: 0.7362\n",
      "Epoch 104/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4966 - accuracy: 0.7394\n",
      "Epoch 105/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4942 - accuracy: 0.7410\n",
      "Epoch 106/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4943 - accuracy: 0.7541\n",
      "Epoch 107/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4955 - accuracy: 0.7541\n",
      "Epoch 108/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4805 - accuracy: 0.7476\n",
      "Epoch 109/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4889 - accuracy: 0.7590\n",
      "Epoch 110/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5116 - accuracy: 0.7378\n",
      "Epoch 111/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4908 - accuracy: 0.7427\n",
      "Epoch 112/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4882 - accuracy: 0.7590\n",
      "Epoch 113/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4955 - accuracy: 0.7492\n",
      "Epoch 114/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4880 - accuracy: 0.7476\n",
      "Epoch 115/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4882 - accuracy: 0.7655\n",
      "Epoch 116/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5208 - accuracy: 0.7117\n",
      "Epoch 117/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4849 - accuracy: 0.7459\n",
      "Epoch 118/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4884 - accuracy: 0.7492\n",
      "Epoch 119/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4914 - accuracy: 0.7459\n",
      "Epoch 120/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4825 - accuracy: 0.7508\n",
      "Epoch 121/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4950 - accuracy: 0.7443\n",
      "Epoch 122/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4857 - accuracy: 0.7541\n",
      "Epoch 123/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4900 - accuracy: 0.7590\n",
      "Epoch 124/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4781 - accuracy: 0.7508\n",
      "Epoch 125/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5013 - accuracy: 0.7329\n",
      "Epoch 126/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4789 - accuracy: 0.7492\n",
      "Epoch 127/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4851 - accuracy: 0.7557\n",
      "Epoch 128/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4783 - accuracy: 0.7557\n",
      "Epoch 129/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4812 - accuracy: 0.7638\n",
      "Epoch 130/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4893 - accuracy: 0.7492\n",
      "Epoch 131/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4784 - accuracy: 0.7573\n",
      "Epoch 132/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4804 - accuracy: 0.7573\n",
      "Epoch 133/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4912 - accuracy: 0.7638\n",
      "Epoch 134/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4733 - accuracy: 0.7655\n",
      "Epoch 135/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4868 - accuracy: 0.7557\n",
      "Epoch 136/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4775 - accuracy: 0.7557\n",
      "Epoch 137/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4772 - accuracy: 0.7508\n",
      "Epoch 138/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4817 - accuracy: 0.7541\n",
      "Epoch 139/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4786 - accuracy: 0.7590\n",
      "Epoch 140/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4923 - accuracy: 0.7557\n",
      "Epoch 141/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4794 - accuracy: 0.7573\n",
      "Epoch 142/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4738 - accuracy: 0.7655\n",
      "Epoch 143/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4833 - accuracy: 0.7541\n",
      "Epoch 144/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4760 - accuracy: 0.7638\n",
      "Epoch 145/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5024 - accuracy: 0.7524\n",
      "Epoch 146/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4731 - accuracy: 0.7524\n",
      "Epoch 147/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4713 - accuracy: 0.7622\n",
      "Epoch 148/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4721 - accuracy: 0.7736\n",
      "Epoch 149/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4820 - accuracy: 0.7752\n",
      "Epoch 150/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4798 - accuracy: 0.7590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fa97467a9a0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the keras Model\n",
    "\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7030 - accuracy: 0.6753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 67.53\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# make class predictions with the model\n",
    "\n",
    "\n",
    "predictions = (model.predict(X_test) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted value [1] and expected value 0\n",
      "predicted value [0] and expected value 0\n",
      "predicted value [0] and expected value 0\n",
      "predicted value [0] and expected value 0\n",
      "predicted value [1] and expected value 0\n",
      "predicted value [1] and expected value 0\n",
      "predicted value [0] and expected value 0\n",
      "predicted value [0] and expected value 0\n",
      "predicted value [1] and expected value 0\n",
      "predicted value [1] and expected value 0\n",
      "predicted value [1] and expected value 1\n",
      "predicted value [1] and expected value 0\n",
      "predicted value [0] and expected value 1\n",
      "predicted value [0] and expected value 0\n",
      "predicted value [0] and expected value 0\n",
      "predicted value [1] and expected value 1\n",
      "predicted value [0] and expected value 0\n",
      "predicted value [0] and expected value 0\n",
      "predicted value [0] and expected value 1\n",
      "predicted value [0] and expected value 1\n"
     ]
    }
   ],
   "source": [
    "# summarize the first 5 cases\n",
    "for i in range(20):\n",
    "    print(f'predicted value {predictions[i]} and expected value {np.array(y_test)[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ainimesh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
