{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vNUWtNOnwPN"
      },
      "source": [
        "# **<center> Assignment-1 </center>**\n",
        "\n",
        "## **<center> Instructions </center>**\n",
        "\n",
        "This Assignment is a coding assignemnt, which covers the following areas:\n",
        "1. Deep Learning  (Feed Forward Neural Network)\n",
        "2. Convolutional Neural Networks\n",
        "3. Recurrent Neural Networks\n",
        "4. LSTM (Long Short Term Memory)\n",
        "\n",
        "``Language to be used - Preferred: Python [or Any Language]``\n",
        "\n",
        "``Framework - Preferred: PyTorch [or Any Framework]``\n",
        "    \n",
        "###  **Submission Instructions**\n",
        "\n",
        "Please Submit the solution notebook with the name convention as **Assignment1_rollnumber_name.ipynb** or **Assignment1_rollnumber_name.py**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FmB2VtYnwPO"
      },
      "source": [
        "## **Problem Statement-1**\n",
        "\n",
        "Given the <a href = \"https://pytorch.org/vision/main/generated/torchvision.datasets.FashionMNIST.html#torchvision.datasets.FashionMNIST\"> FashionMNIST Dataset </a>, which is similar to the MNIST dataset discussed in the class, and skeleton code where ever it's required you are to write the code for the following experiments and report the final metrics.\n",
        "\n",
        "### **Experiments**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_cNm3DFnwPP"
      },
      "source": [
        "#### Performing Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hf4fkNqnwPP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F          # adds some efficiency\n",
        "from torch.utils.data import DataLoader  # lets us load data in batches\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.metrics import confusion_matrix  # for evaluating results\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# dataset\n",
        "from torchvision.datasets import EMNIST, MNIST, FashionMNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFTi6HR5nwPP"
      },
      "source": [
        "#### Loading the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzr4InXpnwPP"
      },
      "outputs": [],
      "source": [
        "# train and test data\n",
        "\n",
        "train_data = datasets.FashionMNIST(root='./dataset', train=True, download=False, transform=transforms.ToTensor()) # do download = True if you have not downloaded it yet\n",
        "test_data = datasets.FashionMNIST(root='./dataset', train=False, download=False, transform=transforms.ToTensor()) # do download = True if you have not downloaded it yet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4dzBTB8nwPP"
      },
      "source": [
        "#### **Experiment:1 [Not Graded]**\n",
        "\n",
        "Explore the dataset and visualize it.\n",
        "\n",
        "1. How many classes are there in the datset ?\n",
        "2. How input image looks ?\n",
        "3. What is the dimension of input data ?\n",
        "4. Do we need any kind of data preprocessing etc ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPama0TgnwPQ"
      },
      "outputs": [],
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o59CifZ7nwPQ"
      },
      "source": [
        "#### **Sudo code for 1 layer neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQkxvD1JnwPQ"
      },
      "outputs": [],
      "source": [
        "class SimpleNeuralNetwork(nn.Module):\n",
        "    def __inint__(self,input_size = 784, output_size = 10, layers =[120,10]):\n",
        "        super().__init__()\n",
        "        self.input_layer = nn.Linear(input_size,layers[0])\n",
        "        self.output_layer = nn.Linear(layers[0], layers[1])\n",
        "\n",
        "    def forward(self,X):\n",
        "        X = F.relu(self.input_layer(X))\n",
        "        X = self.output_layer(X)\n",
        "        return F.log_softmax(X, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPZmKFtznwPQ"
      },
      "source": [
        "#### **Experiment:2 [Graded]**\n",
        "\n",
        "***Design three models with the names***\n",
        "\n",
        "1. ``SimpleNeuralNetwork1``: [784-256-128-10]\n",
        "2. ``SimpleNeuralNetwork2``: [784-203-203-203-10]\n",
        "3. ``SimpleNeuralNetwork3``: [784-512-256-125-75-10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9HwfWR3nwPQ"
      },
      "outputs": [],
      "source": [
        "# Solution:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w205jyuUnwPQ"
      },
      "source": [
        "#### **Experiment:3 [Graded]**\n",
        "\n",
        "***Perform the Training for each of the models by keeping the parameters as:***\n",
        "\n",
        "**``Condition-1``**\n",
        "1. ```Optimizer - ADAM; Batch Size = 64```\n",
        "\n",
        "For this do the experiments using these various learning Rates:\n",
        "\n",
        "take Learning rates as:\n",
        "\n",
        "a. 0.001\n",
        "\n",
        "b. 0.01\n",
        "\n",
        "c. 0.1\n",
        "\n",
        "**``Condition-2``**\n",
        "\n",
        "2. ```Optimizer - SGD with momentum as 0.9; Batch Size = 64```\n",
        "\n",
        "For this do the experiments using these various learning Rates:\n",
        "\n",
        "take Learning rates as:\n",
        "\n",
        "a. 0.001\n",
        "\n",
        "b. 0.01\n",
        "\n",
        "c. 0.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwGiIl1BnwPQ"
      },
      "outputs": [],
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGM3UMqAnwPQ"
      },
      "source": [
        "#### **Experiment:4 [Graded]**\n",
        "\n",
        "***Run all the models for 200 Epochs and report the following***\n",
        "\n",
        "**For all three models run experiments for condition:1 and condition:2**\n",
        "\n",
        "Report the test accuracy in table form for all the models.\n",
        "\n",
        "Pot the training loss vs epoch graph for all the learning rates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgspFr8BnwPR"
      },
      "outputs": [],
      "source": [
        "# solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbW8JhvNnwPR"
      },
      "source": [
        "## **Problem Statement-2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2DCWV2xnwPR"
      },
      "source": [
        "Given the <a href = \"https://pytorch.org/vision/stable/generated/torchvision.datasets.CIFAR10.html#torchvision.datasets.CIFAR10\"> CIFAR-10 Dataset </a>, which consists of 60000 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. Write the code for the following experiments and report the final metrics along with plots.\n",
        "\n",
        "### **Experiments**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Performing Imports"
      ],
      "metadata": {
        "id": "_lO_aF39uKvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Solution"
      ],
      "metadata": {
        "id": "TyA_Cf-xGXiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Experiment:1 Load & Split CIFER-10 dataset [Graded]**\n",
        "\n",
        "#### 1. Load train and test set\n",
        "#### 2. Split train dataset into - train(40000 examples) and val set(10000 examples) using random_split from torch.utils.data."
      ],
      "metadata": {
        "id": "oUtnzFxsGR-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Solution"
      ],
      "metadata": {
        "id": "TVY4SzWAGZYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Experiment:2 Explore & Visualize dataset [Graded]**\n",
        "\n",
        "Explore the dataset and visualize it.\n",
        "\n",
        "1. How input image looks (1 for each class)?\n",
        "2. What is the dimension of input data ?\n",
        "3. Do we need any kind of data preprocessing etc ?"
      ],
      "metadata": {
        "id": "RdH-krrSw-l8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Solution"
      ],
      "metadata": {
        "id": "HJEUytk47bMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Experiment:3 Define CNN architecture creating a class as ```ConvolutionalNN(nn.Module)``` with following [Graded]**\n",
        "\n",
        "1. ```__init__()``` function\n",
        "\n",
        "  ```nn.Conv2d(3, 128, 5, padding=2)```\n",
        "\n",
        "  ```nn.Conv2d(128, 128, 5, padding=2)```\n",
        "\n",
        "  ```nn.Conv2d(128, 256, 3, padding=1)```\n",
        "\n",
        "  ```nn.Conv2d(256, 256, 3, padding=1)```\n",
        "\n",
        "  ```nn.MaxPool2d(2, 2)```\n",
        "\n",
        "  ```nn.BatchNorm2d(128)```\n",
        "\n",
        "  ```nn.BatchNorm2d(128)```\n",
        "\n",
        "  ```nn.BatchNorm2d(256)```\n",
        "\n",
        "  ```nn.BatchNorm2d(256)```\n",
        "\n",
        "  ```nn.BatchNorm1d(1024)```\n",
        "\n",
        "  ```nn.BatchNorm1d(512)```\n",
        "\n",
        "  ```nn.Dropout2d(p=0.25)```\n",
        "\n",
        "  ```nn.Dropout(p=0.5)```\n",
        "\n",
        "  ```nn.Linear(256 * 8 * 8, 1024)```\n",
        "\n",
        "  ```nn.Linear(1024, 512)```\n",
        "\n",
        "  ```nn.Linear(512, 10)```\n",
        "\n",
        "2. ```forward(self, x)```"
      ],
      "metadata": {
        "id": "8UDQiQcAIUAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Solution"
      ],
      "metadata": {
        "id": "uXHXEwKBKF4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Experiment:4 Instantiates ```ConvolutionalNN``` & calculate total trainable parameters [Graded]**\n"
      ],
      "metadata": {
        "id": "Jw7yzV7-KjtO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Solution"
      ],
      "metadata": {
        "id": "fejOKT8K-Rxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Experiment:5 Model training [Graded]**\n",
        "\n",
        "Perform the Training by keeping the parameters as:\n",
        "\n",
        "Epochs - ```100```\n",
        "\n",
        "Batch size  - ```64```\n",
        "\n",
        "Optimizer - ```Adam``` with ```lr=0.01```, ```betas=(0.9, 0.999)```, ```eps=1e-08```, ```weight_decay=0.1```"
      ],
      "metadata": {
        "id": "BqBLBLq5-QLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Solution"
      ],
      "metadata": {
        "id": "J9R8c6zAMj3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Experiment:6 Accuracy & Loss plots [Graded]**\n",
        "\n",
        "1. training v/s validation loss plot over epochs\n",
        "2. training v/s validation accuracy plot over epochs"
      ],
      "metadata": {
        "id": "2c9suAoZNUvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Solution"
      ],
      "metadata": {
        "id": "1YjKaxL6Nmeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Experiment:7 Evaluate model on test set [Graded]**\n",
        "\n",
        "1. Compute confusion metric\n",
        "2. Compute accuracy\n",
        "3. classification report"
      ],
      "metadata": {
        "id": "7IuMkewaOMi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Solution"
      ],
      "metadata": {
        "id": "buMDIMxjOnDg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ainimesh",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}